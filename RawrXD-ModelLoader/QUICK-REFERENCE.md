# RawrXD Model Loader - Quick Reference

## ğŸš€ Quick Start

### 1. Install Prerequisites (5-10 minutes each)
```
Download and install in this order:
1. Visual Studio 2022 - https://visualstudio.microsoft.com/
2. CMake - https://cmake.org/download/
3. Vulkan SDK - https://vulkan.lunarg.com/sdk/home
```

### 2. Build Project (5 minutes)
```powershell
cd "c:\Users\HiH8e\OneDrive\Desktop\Powershield\RawrXD-ModelLoader"
.\build.ps1
```

### 3. Run Application (Immediate)
```powershell
.\build\bin\Release\RawrXD-ModelLoader.exe
```

Expected: System tray icon appears, API server on port 11434

---

## ğŸ“ Project Files at a Glance

| File | Purpose | Lines | Status |
|------|---------|-------|--------|
| `main.cpp` | Entry point, system tray | 250+ | âœ“ Complete |
| `gguf_loader.cpp` | GGUF parser | 350+ | âœ“ Complete |
| `vulkan_compute.cpp` | GPU backend | 400+ | âœ“ Complete |
| `hf_downloader.cpp` | Model downloads | 200+ | âœ“ Complete |
| `gui.cpp` | ImGui interface | 150+ | âœ“ Complete |
| `api_server.cpp` | HTTP APIs | 150+ | âœ“ Complete |
| **7 Shaders** | GPU compute kernels | 500+ | âœ“ Complete |

---

## ğŸ”§ Key Commands

### Build Commands
```powershell
# Automated build with defaults
.\build.ps1

# Clean rebuild
.\build.ps1 -CleanBuild

# Debug build
.\build.ps1 -Configuration Debug

# Skip shader compilation
.\build.ps1 -SkipShaderCompile
```

### Manual Build
```powershell
cd build
cmake .. -G "Visual Studio 17 2022"
cmake --build . --config Release
```

### Compile Shaders Only
```powershell
cd shaders
& "$env:VULKAN_SDK\bin\glslc.exe" -O *.glsl  # All shaders
```

### Run Application
```powershell
.\build\bin\Release\RawrXD-ModelLoader.exe
```

### Test API
```powershell
# List models
curl http://localhost:11434/api/tags

# Generate text
curl -X POST http://localhost:11434/api/generate `
  -H "Content-Type: application/json" `
  -d '{"model":"model-name","prompt":"hello"}'

# Chat completion (OpenAI format)
curl -X POST http://localhost:11434/v1/chat/completions `
  -H "Content-Type: application/json" `
  -d '{"model":"model-name","messages":[{"role":"user","content":"hello"}]}'
```

---

## ğŸ¯ Architecture Overview

```
RawrXD-ModelLoader
â”œâ”€ GGUF Loader â†’ Binary parsing (no external libs)
â”œâ”€ Vulkan GPU â†’ AMD 7800XT optimized compute
â”œâ”€ HuggingFace â†’ Model discovery & download
â”œâ”€ ImGui GUI â†’ Chat interface & settings
â”œâ”€ HTTP API â†’ Ollama + OpenAI compatible
â””â”€ System Tray â†’ Background service

All connected via AppState global struct
```

---

## ğŸ“Š Component Dependencies

```
main.cpp
â”œâ”€ gui.h/cpp â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€ imGui (header-only)
â”œâ”€ gguf_loader.h/cpp   â”‚
â”œâ”€ vulkan_compute.h/cppâ”‚â”€ Vulkan SDK
â”œâ”€ hf_downloader.h/cpp â”‚
â””â”€ api_server.h/cpp â”€â”€â”€â””â”€ Windows APIs

No external runtime dependencies!
(All critical libs are header-only or OS-provided)
```

---

## ğŸ” Troubleshooting Quick Fixes

| Problem | Solution |
|---------|----------|
| "VULKAN_SDK not set" | Download Vulkan SDK, set `$env:VULKAN_SDK = "C:\VulkanSDK\1.3.xxx"` |
| "CMake not found" | Download from cmake.org, add to PATH |
| "Shader compilation fails" | Verify `glslc.exe` in `$env:VULKAN_SDK\bin` |
| "Device not detected" | Ensure AMD drivers are updated, run vulkaninfo |
| "Port 11434 in use" | Close other Ollama instances, check: `netstat -ano \| findstr :11434` |
| "Build errors" | Delete `build` folder, reconfigure, check CMake version â‰¥ 3.20 |

---

## ğŸ“‹ Files Checklist

**Headers (include/):**
- [x] gguf_loader.h
- [x] vulkan_compute.h
- [x] hf_downloader.h
- [x] gui.h
- [x] api_server.h

**Sources (src/):**
- [x] main.cpp
- [x] gguf_loader.cpp
- [x] vulkan_compute.cpp
- [x] hf_downloader.cpp
- [x] gui.cpp
- [x] api_server.cpp

**Shaders (shaders/):**
- [x] matmul.glsl
- [x] attention.glsl
- [x] rope.glsl
- [x] rmsnorm.glsl
- [x] softmax.glsl
- [x] silu.glsl
- [x] dequant.glsl

**Build Config:**
- [x] CMakeLists.txt
- [x] build.ps1

**Documentation:**
- [x] README.md (400+ lines)
- [x] SETUP.md (300+ lines)
- [x] IMPLEMENTATION-SUMMARY.md (600+ lines)
- [x] QUICK-REFERENCE.md (this file)

---

## ğŸ® GPU Capabilities

**AMD 7800XT (RDNA3)**:
- Peak FP32: 19.2 TFLOPS
- Compute Units: 60
- Max Memory: 20GB GDDR6
- Optimized for: Wave64, LDS shared memory, matrix ops

**Our Optimization**:
- Wave64 work groups
- 16Ã—16 thread blocks (optimal occupancy)
- Shared memory tiling for matmul
- Minimal register pressure

---

## ğŸ“ˆ Performance Expectations

- **Startup**: ~2-3 seconds (GPU init + window creation)
- **Model Load**: ~5-10 seconds per zone (512MB)
- **Token Generation**: 5-10 tokens/sec (16B model, Q2_K)
- **Memory Overhead**: ~50MB (index only)
- **API Response**: <100ms per inference call

---

## ğŸ”— Integration Guide

### With RawrXD.ps1 IDE
```powershell
# Query models
$models = Invoke-RestMethod "http://localhost:11434/api/tags"

# Send prompt
$result = Invoke-RestMethod -Uri "http://localhost:11434/api/generate" `
  -Method POST -Body @{model="model-name"; prompt=$input}
```

### With External Tools
```bash
# Ollama-compatible API (drop-in replacement)
ollama pull localhost:11434/model-name
ollama run localhost:11434/model-name "prompt"

# Or via curl
curl http://localhost:11434/api/generate -d '{"model":"name","prompt":"text"}'
```

### Model Storage
```
Models Directory: %USERPROFILE%\RawrXD\models\
Expected Format: *.gguf files
Example: BigDaddyG-Q2_K-PRUNED-16GB.gguf
```

---

## ğŸ› ï¸ Development Tips

### For Development Builds
```powershell
# Debug configuration
.\build.ps1 -Configuration Debug

# Attaches Visual Studio debugger automatically
```

### Profiling Performance
```powershell
# Monitor GPU usage during inference
gpu-z.exe  # Third-party GPU monitor

# Or use Windows Performance Analyzer
wpa.exe
```

### Shader Debugging
```bash
# Recompile individual shader with verbose output
& "$env:VULKAN_SDK\bin\glslc.exe" shader.glsl -o shader.spv -v
```

---

## ğŸ“š Key Concepts

### GGUF Format
- Binary model file format (v3 supported)
- Metadata KV pairs describe model (llama architecture, 53 layers, 8192 embedding dim)
- 480 tensors for BigDaddyG
- Quantized weights save 75% storage vs. FP32

### Zone-Based Streaming
- Divide model into ~512MB zones
- Load zone to GPU only when needed
- Unload oldest zone when cache fills
- Matches transformer layer structure

### Vulkan Compute
- GPU compute shader pipeline
- SPIR-V (compiled GLSL) for portability
- Multiple kernels: matmul, attention, activation functions
- AMD RDNA3 optimized (7800XT)

### Ollama API Compatibility
- Drop-in replacement for local Ollama
- Same endpoints: /api/generate, /api/tags, /api/pull
- Same response formats (JSON)
- RawrXD IDE can use without code changes

---

## ğŸš¨ Common Errors & Fixes

```
Error: "Cannot open include file: 'vulkan/vulkan.h'"
Fix: Set CMAKE_PREFIX_PATH or reinstall Vulkan SDK

Error: "LNK2019 unresolved external symbol"
Fix: Ensure all libraries linked in CMakeLists.txt

Error: "Vulkan device not found"
Fix: Run 'vulkaninfo' to verify GPU driver, update AMD drivers

Error: "GLSL shader compilation failed"
Fix: Check syntax, validate with glslang-validator, try older glslc version
```

---

## ğŸ“ Support

1. **README.md** - Full feature documentation
2. **SETUP.md** - Step-by-step installation guide
3. **IMPLEMENTATION-SUMMARY.md** - Detailed architecture
4. **Code Comments** - Inline documentation in source files
5. **CMakeLists.txt** - Build configuration explanations

---

## âœ… Status

**Project Status**: âœ“ **FULLY IMPLEMENTED**

- Source Code: Complete (6 .cpp + 5 .h files)
- GPU Shaders: Complete (7 .glsl files)
- Build System: Complete (CMakeLists.txt + build.ps1)
- Documentation: Complete (4 .md files)
- Ready for: Compilation and deployment

**Next Action**: Run `.\build.ps1` to compile

---

**Last Updated**: November 29, 2025  
**Version**: 1.0  
**Status**: Ready for Build
