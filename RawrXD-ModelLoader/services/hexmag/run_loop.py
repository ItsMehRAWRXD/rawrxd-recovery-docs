import asyncio
from typing import List
from core.contracts import Event, Finding
from core.registry import load_bots

class Engine:
    """
    The main execution loop for the HexMag swarm.
    """
    def __init__(self):
        self.q: List[Event] = []
        self.history: List[Finding] = []
        self.event_count = 0
        self.bots = load_bots()
        print(f"Engine initialized with {len(self.bots)} bots.")

    def add(self, event: Event) -> None:
        """Add an event to the processing queue."""
        self.q.append(event)

    async def step(self) -> None:
        """
        Process one step of the swarm loop.
        Routes events to appropriate handlers and generates findings.
        """
        if not self.q:
            await asyncio.sleep(0.01)
            return

        # Pop the next event
        event = self.q.pop(0)
        self.event_count += 1
        
        # Dispatch to bots
        tasks = []
        for bot in self.bots:
            if bot.supports(event):
                tasks.append(bot.run(event))
        
        if tasks:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            for res in results:
                if isinstance(res, list):
                    self.history.extend(res)
                elif isinstance(res, Exception):
                    print(f"Bot error: {res}")

        # Fallback if no bots handled it (for basic Q&A if no bot matched)
        # We check if any finding was generated for this event (conceptually)
        # But since we don't track which finding belongs to which event easily here without ID,
        # we'll just do a quick check if we need to generate a default answer.
        
        # If it was a question and no bot responded, use the default generator
        if event.kind == "llm.question":
            # Check if we got an answer in history recently? 
            # Simplification: Just run the default generator if no bots are loaded or none matched?
            # For now, let's keep the default generator as a fallback if no bots are loaded.
            if not self.bots:
                 self._run_default_logic(event)
            else:
                 # If bots exist, we assume they handled it. 
                 # But if the codegen bot didn't match, we might want a fallback.
                 # Let's check if any finding was added.
                 pass

    def _run_default_logic(self, event: Event):
        if event.kind == "llm.question":
            question = event.payload.get("question", "")
            answer = self._generate_answer(question)
            finding = Finding(
                bot="HexMag-Engine",
                score=1.0,
                labels={"llm.answer"},
                rationale="Direct answer generated by HexMag engine",
                data={"answer": answer, "question": question}
            )
            self.history.append(finding)
    
    def _generate_answer(self, question: str) -> str:
        """
        Generate a contextual answer to the question.
        This is a simple implementation - in production, this would call an LLM.
        """
        q_lower = question.lower()
        
        # Handle common programming questions
        if "hello world" in q_lower or "hello, world" in q_lower:
            if "python" in q_lower:
                return 'print("Hello, World!")'
            elif "javascript" in q_lower or "js" in q_lower:
                return 'console.log("Hello, World!");'
            elif "c++" in q_lower or "cpp" in q_lower:
                return '#include <iostream>\nint main() {\n    std::cout << "Hello, World!" << std::endl;\n    return 0;\n}'
            elif "java" in q_lower:
                return 'public class Main {\n    public static void main(String[] args) {\n        System.out.println("Hello, World!");\n    }\n}'
            else:
                return 'print("Hello, World!")  # Python example'
        
        # Handle math questions
        if "2+2" in q_lower or "2 + 2" in q_lower:
            return "2 + 2 = 4"
        
        if "quantum computing" in q_lower:
            return ("Quantum computing leverages quantum mechanical phenomena like superposition and entanglement "
                    "to process information. Unlike classical bits (0 or 1), quantum bits (qubits) can exist in "
                    "multiple states simultaneously, enabling parallel computation for certain problems.")
        
        # Default response with context awareness
        if "?" in question:
            return f"Based on your question about '{question[:50]}...', I can help you explore this topic. The HexMag engine is processing your request and analyzing the context provided."
        
        return f"Processing request: {question[:100]}... The HexMag swarm engine has received your input and is generating a contextual response."
